#!/usr/bin/env python3

from zhipuai import ZhipuAI
from colorama import Fore, Style
import sys
import time
import jwt
import requests
import json


api_key="********"

#def generate_token(apikey: str, exp_seconds: int):
#    try:
#        id, secret = apikey.split(".")
#    except Exception as e:
#        raise Exception("invalid apikey", e)
#
#    payload = {
#        "api_key": id,
#        "exp": int(round(time.time() * 1000)) + exp_seconds * 1000,
#        "timestamp": int(round(time.time() * 1000)),
#    }
#
#    return jwt.encode(
#        payload,
#        secret,
#        algorithm="HS256",
#        headers={"alg": "HS256", "sign_type": "SIGN"},
#    )


class GLM_Shell():
    def __init__(self, api_key = None) -> None:
        if api_key == None:
            self.api_key = "********"
        else:
            self.api_key = api_key

        self.message=[]
        self.user_content=''
        self.assistant_content=''

    def set_user_content(self, user_content):
        self.user_content = user_content
    
    def set_assistant_content(self, assistant_content):
        self.assistant_content = assistant_content 

    def add_role_message(self):
        self.message.append({"role": "user", "content": self.user_content})

    def add_assistant_message(self):
        self.message.append({"role": "assistant", "content": self.assistant_content})

    def print_prompt(self):
        print(Fore.LIGHTBLUE_EX+"User: ",end='')
        print(Style.RESET_ALL)
        print(self.user_content)
        print(Fore.LIGHTGREEN_EX+"Assistant: ",end='')
        print(Style.RESET_ALL)


    def generate_token(self, exp_seconds: int):
        try:
            id, secret = self.api_key.split(".")
        except Exception as e:
            raise Exception("invalid apikey", e)

        payload = {
            "api_key": id,
            "exp": int(round(time.time() * 1000)) + exp_seconds * 1000,
            "timestamp": int(round(time.time() * 1000)),
        }

        return jwt.encode(
            payload,
            secret,
            algorithm="HS256",
            headers={"alg": "HS256", "sign_type": "SIGN"},
        )

    def single_chat(self):
        response = requests.post(
            'https://open.bigmodel.cn/api/paas/v4/chat/completions',
            headers={
                "Authorization": self.generate_token(6000),
                "Content-Type": "application/json"
            },
            data=json.dumps({
                "model": 'glm-4',
                "messages": self.message,
            })
        )
        return response
    
    def single_turn_chat(self):
        user_content=''
        for arg in sys.argv[1:]:
            user_content+=arg+" "
        
        self.set_user_content(user_content)
        self.add_role_message()
        self.print_prompt()
        response = self.single_chat()
        assistant_content = json.loads(response.text)['choices'][0]['message']['content']
        self.set_assistant_content(assistant_content)
        self.add_assistant_message()
        print(self.assistant_content)
        print("\n(end)")


    def multi_turns_chat(self):
        while(1):
            print(Fore.LIGHTYELLOW_EX+"Chat>",end='')
            print(Style.RESET_ALL, end='')
            user_content=input()
            self.set_user_content(user_content)
            if(self.user_content == 'q'):
                print(Fore.LIGHTRED_EX+"Quit Chat"+Style.RESET_ALL)
                return
            self.add_role_message()
            self.print_prompt()
            response = self.single_chat()
            assistant_content = json.loads(response.text)['choices'][0]['message']['content']
            self.set_assistant_content(assistant_content)
            self.add_assistant_message()
            print(self.assistant_content)
            print("\n(end)")


def main():
    glm_shell=GLM_Shell(api_key=api_key)
    #client = ZhipuAI(api_key="2912857228b2930e8669c3138f3a3753.91jfFT0NGUWu555L" )
    if len(sys.argv) == 1:

        glm_shell.multi_turns_chat()

        #messages=[]
        #while(1):
        #    print(Fore.LIGHTYELLOW_EX+"Chat>",end='')
        #    print(Style.RESET_ALL, end='')
        #    user_content=input()
        #    if(user_content=='q'):
        #        print(Fore.LIGHTRED_EX+"Quit Chat"+Style.RESET_ALL)
        #        exit()
        #    messages.append({"role": "user", "content": user_content})
        #    response = client.chat.completions.create(
        #        model="glm-4",  
        #        messages=messages,
        #        stream=True,
        #    )
        #    print(Fore.LIGHTBLUE_EX+"User: ",end='')
        #    print(Style.RESET_ALL)
        #    print(user_content)
        #    print(Fore.LIGHTGREEN_EX+"Assistant: ",end='')
        #    print(Style.RESET_ALL)
        #    assistant_conntent=""
        #    for chunk in response:
        #        assistant_conntent+=chunk.choices[0].delta.content
        #        print(chunk.choices[0].delta.content,end='')
        #    messages.append({"role": "assistant", "content": assistant_conntent})
        #    print("\n(end)")
    
    else:
        
        glm_shell.single_turn_chat()

        #print(Fore.LIGHTBLUE_EX+"User: ",end='')
        #print(Style.RESET_ALL)
        #print(user_content)
        #print(Fore.LIGHTGREEN_EX+"Assistant: ",end='')
        #print(Style.RESET_ALL)

        #response = requests.post(
        #    'https://open.bigmodel.cn/api/paas/v4/chat/completions',
        #    headers={
        #        "Authorization": generate_token("2912857228b2930e8669c3138f3a3753.91jfFT0NGUWu555L", 6000),
        #        "Content-Type": "application/json"
        #    },
        #    data=json.dumps({
        #        "model": 'glm-4',
        #        "messages": [
        #            {"role": "user", "content": user_content},
        #        ],
        #    })
        #)

        #response = client.chat.completions.create(
        #    model="glm-4",  
        #    messages=[
        #        {"role": "user", "content": user_content},
        #    ],
        #    stream=True,
        #)


        #for chunk in response:
        #    print(chunk.choices[0].delta.content,end='')

if __name__ == "__main__":
    main()
